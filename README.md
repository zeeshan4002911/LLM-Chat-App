# LLM-Chat-App

Steps to run the app
1. Install Dependency packages
    pip install streamlit llama-index llama-index-llms-ollama
2. Download Ollama https://ollama.com
    ollama pull phi3/llama3
3. For running the application
    streamlit run ollama-streamlit-app.py

Note: It requires good amount of system resources to run the LLM models (RAM + GPU)
